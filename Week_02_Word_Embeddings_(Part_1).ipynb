{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week 02 - Word Embeddings (Part 1).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subhobrata/NLP_Exercises/blob/master/Week_02_Word_Embeddings_(Part_1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "wWzU9hqUomdU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "3d418ea6-c7c5-44cd-a68e-4478e6fa7dcc"
      },
      "cell_type": "code",
      "source": [
        "!wget -O quora.zip -qq --no-check-certificate \"https://drive.google.com/uc?export=download&id=1ERtxpdWOgGQ3HOigqAMHTJjmOE_tWvoF\"\n",
        "!unzip quora.zip\n",
        "!pip install -q --upgrade nltk gensim bokeh pandas\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  quora.zip\n",
            "  inflating: train.csv               \n",
            "\u001b[K    100% |████████████████████████████████| 1.4MB 14.9MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 24.2MB 1.5MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 17.5MB 2.3MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 10.1MB 3.7MB/s \n",
            "\u001b[?25h  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Building wheel for bokeh (setup.py) ... \u001b[?25ldone\n",
            "\u001b[31mfastai 1.0.51 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "VXl16AOdtlDk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Word embeddings"
      ]
    },
    {
      "metadata": {
        "id": "ErZ_TOu0vAOR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* Nb. The notebook is heavily based on [the first assignment from the relevant ShAD course] (https://github.com/yandexdataschool/nlp_course/tree/master/week1_embeddings). *\n",
        "\n",
        "Everyone saw these pictures (I hope):\n",
        "! [embeddings relations] (https://www.tensorflow.org/images/linear-relationships.png)\n",
        "* From [Vector Representations of Words, Tensorflow tutorial] (https://www.tensorflow.org/tutorials/representation/word2vec) *\n",
        "\n",
        "Today we will deal with such models.\n",
        "\n",
        "Let's start the morning with visualizations. We go to the site [http://rusvectores.org/ru/ru/ruhhhtpp/rusvectores.org/ru/) and see what the trained models for Russian can do.\n",
        "\n",
        "Note the sections * Related words * and * Calculator *, as well as the set of models that you can choose from."
      ]
    },
    {
      "metadata": {
        "id": "FkxsGQqZNjxj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "## We train a simple model"
      ]
    },
    {
      "metadata": {
        "id": "PaOn69Bg1hH-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "It’s just not fun to just look at other people's models, so we’ll gradually come closer to solving a specific task: [Quora Question Pairs at kaggle](https://www.kaggle.com/c/quora-question-pairs):"
      ]
    },
    {
      "metadata": {
        "id": "K-X7I7nc1gyS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1969
        },
        "outputId": "b2e33e7b-f431-4571-ad5f-00e7e19c55b4"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "quora_data = pd.read_csv('train.csv')\n",
        "\n",
        "quora_data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
              "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>Should I buy tiago?</td>\n",
              "      <td>What keeps childern active and far from phone ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>How can I be a good geologist?</td>\n",
              "      <td>What should I do to be a great geologist?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>When do you use シ instead of し?</td>\n",
              "      <td>When do you use \"&amp;\" instead of \"and\"?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>19</td>\n",
              "      <td>20</td>\n",
              "      <td>Motorola (company): Can I hack my Charter Moto...</td>\n",
              "      <td>How do I hack Motorola DCX3400 for free internet?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>21</td>\n",
              "      <td>22</td>\n",
              "      <td>Method to find separation of slits using fresn...</td>\n",
              "      <td>What are some of the things technicians can te...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>23</td>\n",
              "      <td>24</td>\n",
              "      <td>How do I read and find my YouTube comments?</td>\n",
              "      <td>How can I see all my Youtube comments?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>25</td>\n",
              "      <td>26</td>\n",
              "      <td>What can make Physics easy to learn?</td>\n",
              "      <td>How can you make physics easy to learn?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>27</td>\n",
              "      <td>28</td>\n",
              "      <td>What was your first sexual experience like?</td>\n",
              "      <td>What was your first sexual experience?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>29</td>\n",
              "      <td>30</td>\n",
              "      <td>What are the laws to change your status from a...</td>\n",
              "      <td>What are the laws to change your status from a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>31</td>\n",
              "      <td>32</td>\n",
              "      <td>What would a Trump presidency mean for current...</td>\n",
              "      <td>How will a Trump presidency affect the student...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>33</td>\n",
              "      <td>34</td>\n",
              "      <td>What does manipulation mean?</td>\n",
              "      <td>What does manipulation means?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>35</td>\n",
              "      <td>36</td>\n",
              "      <td>Why do girls want to be friends with the guy t...</td>\n",
              "      <td>How do guys feel after rejecting a girl?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>37</td>\n",
              "      <td>38</td>\n",
              "      <td>Why are so many Quora users posting questions ...</td>\n",
              "      <td>Why do people ask Quora questions which can be...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>39</td>\n",
              "      <td>40</td>\n",
              "      <td>Which is the best digital marketing institutio...</td>\n",
              "      <td>Which is the best digital marketing institute ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>41</td>\n",
              "      <td>42</td>\n",
              "      <td>Why do rockets look white?</td>\n",
              "      <td>Why are rockets and boosters painted white?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>43</td>\n",
              "      <td>44</td>\n",
              "      <td>What's causing someone to be jealous?</td>\n",
              "      <td>What can I do to avoid being jealous of someone?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>45</td>\n",
              "      <td>46</td>\n",
              "      <td>What are the questions should not ask on Quora?</td>\n",
              "      <td>Which question should I ask on Quora?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>47</td>\n",
              "      <td>48</td>\n",
              "      <td>How much is 30 kV in HP?</td>\n",
              "      <td>Where can I find a conversion chart for CC to ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>49</td>\n",
              "      <td>50</td>\n",
              "      <td>What does it mean that every time I look at th...</td>\n",
              "      <td>How many times a day do a clock’s hands overlap?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>51</td>\n",
              "      <td>52</td>\n",
              "      <td>What are some tips on making it through the jo...</td>\n",
              "      <td>What are some tips on making it through the jo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>53</td>\n",
              "      <td>54</td>\n",
              "      <td>What is web application?</td>\n",
              "      <td>What is the web application framework?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>27</td>\n",
              "      <td>55</td>\n",
              "      <td>56</td>\n",
              "      <td>Does society place too much importance on sports?</td>\n",
              "      <td>How do sports contribute to the society?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>28</td>\n",
              "      <td>57</td>\n",
              "      <td>58</td>\n",
              "      <td>What is best way to make money online?</td>\n",
              "      <td>What is best way to ask for money online?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>29</td>\n",
              "      <td>59</td>\n",
              "      <td>60</td>\n",
              "      <td>How should I prepare for CA final law?</td>\n",
              "      <td>How one should know that he/she completely pre...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404260</th>\n",
              "      <td>404260</td>\n",
              "      <td>182494</td>\n",
              "      <td>691</td>\n",
              "      <td>Which phone is best under 12000?</td>\n",
              "      <td>What is the best phone to buy below 15k?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404261</th>\n",
              "      <td>404261</td>\n",
              "      <td>281150</td>\n",
              "      <td>124172</td>\n",
              "      <td>Who is the overall most popular Game of Throne...</td>\n",
              "      <td>Who is the most popular character in the Game ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404262</th>\n",
              "      <td>404262</td>\n",
              "      <td>537905</td>\n",
              "      <td>466328</td>\n",
              "      <td>How do you troubleshoot a Toshiba laptop?</td>\n",
              "      <td>How do I reset a Toshiba laptop?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404263</th>\n",
              "      <td>404263</td>\n",
              "      <td>375195</td>\n",
              "      <td>537906</td>\n",
              "      <td>How does the burning of fossil fuels contribut...</td>\n",
              "      <td>Why does CO2 contribute more to global warming...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404264</th>\n",
              "      <td>404264</td>\n",
              "      <td>537907</td>\n",
              "      <td>537908</td>\n",
              "      <td>Is it safe to store an external battery power ...</td>\n",
              "      <td>How do I make a safe and cheap power bank?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404265</th>\n",
              "      <td>404265</td>\n",
              "      <td>25994</td>\n",
              "      <td>16064</td>\n",
              "      <td>How can I gain weight on my body?</td>\n",
              "      <td>What should I eat to gain weight?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404266</th>\n",
              "      <td>404266</td>\n",
              "      <td>155813</td>\n",
              "      <td>146284</td>\n",
              "      <td>What is the green dot next to the phone icon o...</td>\n",
              "      <td>My boyfriend says he deleted his Facebook Mess...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404267</th>\n",
              "      <td>404267</td>\n",
              "      <td>20171</td>\n",
              "      <td>290649</td>\n",
              "      <td>What are the causes of the fall of the Roman E...</td>\n",
              "      <td>What were the most important causes and effect...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404268</th>\n",
              "      <td>404268</td>\n",
              "      <td>537909</td>\n",
              "      <td>537910</td>\n",
              "      <td>Why don't we still do great music like in the ...</td>\n",
              "      <td>Should I raise my young child on 80's music?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404269</th>\n",
              "      <td>404269</td>\n",
              "      <td>537911</td>\n",
              "      <td>349794</td>\n",
              "      <td>How do you diagnose antisocial personality dis...</td>\n",
              "      <td>What Does It Feel Like to have antisocial pers...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404270</th>\n",
              "      <td>404270</td>\n",
              "      <td>537912</td>\n",
              "      <td>35364</td>\n",
              "      <td>What is the difference between who and how?</td>\n",
              "      <td>What is the difference between \"&amp;\" and \"and\"?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404271</th>\n",
              "      <td>404271</td>\n",
              "      <td>537913</td>\n",
              "      <td>537914</td>\n",
              "      <td>Does Stalin have any grandchildren that are st...</td>\n",
              "      <td>What was Joseph Stalin's 5 year plan? How did ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404272</th>\n",
              "      <td>404272</td>\n",
              "      <td>128018</td>\n",
              "      <td>14005</td>\n",
              "      <td>What are the best new car products or inventio...</td>\n",
              "      <td>What are some mind-blowing vehicles tools that...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404273</th>\n",
              "      <td>404273</td>\n",
              "      <td>537915</td>\n",
              "      <td>537916</td>\n",
              "      <td>What happens if you put milk in a coffee maker?</td>\n",
              "      <td>What would happen if I put milk instead of wat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404274</th>\n",
              "      <td>404274</td>\n",
              "      <td>178643</td>\n",
              "      <td>87385</td>\n",
              "      <td>Will the next generation of parenting change o...</td>\n",
              "      <td>What kind of parents will the next generation ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404275</th>\n",
              "      <td>404275</td>\n",
              "      <td>97922</td>\n",
              "      <td>537917</td>\n",
              "      <td>In accounting, why do we debit expenses and cr...</td>\n",
              "      <td>What is a utilities expense in accounting? How...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404276</th>\n",
              "      <td>404276</td>\n",
              "      <td>24305</td>\n",
              "      <td>308365</td>\n",
              "      <td>What is copilotsearch.com?</td>\n",
              "      <td>What is ContenVania.com?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404277</th>\n",
              "      <td>404277</td>\n",
              "      <td>355668</td>\n",
              "      <td>537918</td>\n",
              "      <td>What does analytics do?</td>\n",
              "      <td>What are analytical people like?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404278</th>\n",
              "      <td>404278</td>\n",
              "      <td>537919</td>\n",
              "      <td>169786</td>\n",
              "      <td>How did you prepare for AIIMS/NEET/AIPMT?</td>\n",
              "      <td>How did you prepare for the AIIMS UG entrance ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404279</th>\n",
              "      <td>404279</td>\n",
              "      <td>537920</td>\n",
              "      <td>537921</td>\n",
              "      <td>What is the minimum time required to build a f...</td>\n",
              "      <td>What is a cheaper and quicker way to build an ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404280</th>\n",
              "      <td>404280</td>\n",
              "      <td>537922</td>\n",
              "      <td>537923</td>\n",
              "      <td>What are some outfit ideas to wear to a frat p...</td>\n",
              "      <td>What are some outfit ideas wear to a frat them...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404281</th>\n",
              "      <td>404281</td>\n",
              "      <td>99131</td>\n",
              "      <td>81495</td>\n",
              "      <td>Why is Manaphy childish in Pokémon Ranger and ...</td>\n",
              "      <td>Why is Manaphy annoying in Pokemon ranger and ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404282</th>\n",
              "      <td>404282</td>\n",
              "      <td>1931</td>\n",
              "      <td>16773</td>\n",
              "      <td>How does a long distance relationship work?</td>\n",
              "      <td>How are long distance relationships maintained?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404283</th>\n",
              "      <td>404283</td>\n",
              "      <td>537924</td>\n",
              "      <td>537925</td>\n",
              "      <td>What do you think of the removal of the MagSaf...</td>\n",
              "      <td>What will the CPU upgrade to the 2016 Apple Ma...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404284</th>\n",
              "      <td>404284</td>\n",
              "      <td>537926</td>\n",
              "      <td>537927</td>\n",
              "      <td>What does Jainism say about homosexuality?</td>\n",
              "      <td>What does Jainism say about Gays and Homosexua...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404285</th>\n",
              "      <td>404285</td>\n",
              "      <td>433578</td>\n",
              "      <td>379845</td>\n",
              "      <td>How many keywords are there in the Racket prog...</td>\n",
              "      <td>How many keywords are there in PERL Programmin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404286</th>\n",
              "      <td>404286</td>\n",
              "      <td>18840</td>\n",
              "      <td>155606</td>\n",
              "      <td>Do you believe there is life after death?</td>\n",
              "      <td>Is it true that there is life after death?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404287</th>\n",
              "      <td>404287</td>\n",
              "      <td>537928</td>\n",
              "      <td>537929</td>\n",
              "      <td>What is one coin?</td>\n",
              "      <td>What's this coin?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404288</th>\n",
              "      <td>404288</td>\n",
              "      <td>537930</td>\n",
              "      <td>537931</td>\n",
              "      <td>What is the approx annual cost of living while...</td>\n",
              "      <td>I am having little hairfall problem but I want...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404289</th>\n",
              "      <td>404289</td>\n",
              "      <td>537932</td>\n",
              "      <td>537933</td>\n",
              "      <td>What is like to have sex with cousin?</td>\n",
              "      <td>What is it like to have sex with your cousin?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>404290 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            id    qid1    qid2  \\\n",
              "0            0       1       2   \n",
              "1            1       3       4   \n",
              "2            2       5       6   \n",
              "3            3       7       8   \n",
              "4            4       9      10   \n",
              "5            5      11      12   \n",
              "6            6      13      14   \n",
              "7            7      15      16   \n",
              "8            8      17      18   \n",
              "9            9      19      20   \n",
              "10          10      21      22   \n",
              "11          11      23      24   \n",
              "12          12      25      26   \n",
              "13          13      27      28   \n",
              "14          14      29      30   \n",
              "15          15      31      32   \n",
              "16          16      33      34   \n",
              "17          17      35      36   \n",
              "18          18      37      38   \n",
              "19          19      39      40   \n",
              "20          20      41      42   \n",
              "21          21      43      44   \n",
              "22          22      45      46   \n",
              "23          23      47      48   \n",
              "24          24      49      50   \n",
              "25          25      51      52   \n",
              "26          26      53      54   \n",
              "27          27      55      56   \n",
              "28          28      57      58   \n",
              "29          29      59      60   \n",
              "...        ...     ...     ...   \n",
              "404260  404260  182494     691   \n",
              "404261  404261  281150  124172   \n",
              "404262  404262  537905  466328   \n",
              "404263  404263  375195  537906   \n",
              "404264  404264  537907  537908   \n",
              "404265  404265   25994   16064   \n",
              "404266  404266  155813  146284   \n",
              "404267  404267   20171  290649   \n",
              "404268  404268  537909  537910   \n",
              "404269  404269  537911  349794   \n",
              "404270  404270  537912   35364   \n",
              "404271  404271  537913  537914   \n",
              "404272  404272  128018   14005   \n",
              "404273  404273  537915  537916   \n",
              "404274  404274  178643   87385   \n",
              "404275  404275   97922  537917   \n",
              "404276  404276   24305  308365   \n",
              "404277  404277  355668  537918   \n",
              "404278  404278  537919  169786   \n",
              "404279  404279  537920  537921   \n",
              "404280  404280  537922  537923   \n",
              "404281  404281   99131   81495   \n",
              "404282  404282    1931   16773   \n",
              "404283  404283  537924  537925   \n",
              "404284  404284  537926  537927   \n",
              "404285  404285  433578  379845   \n",
              "404286  404286   18840  155606   \n",
              "404287  404287  537928  537929   \n",
              "404288  404288  537930  537931   \n",
              "404289  404289  537932  537933   \n",
              "\n",
              "                                                question1  \\\n",
              "0       What is the step by step guide to invest in sh...   \n",
              "1       What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
              "2       How can I increase the speed of my internet co...   \n",
              "3       Why am I mentally very lonely? How can I solve...   \n",
              "4       Which one dissolve in water quikly sugar, salt...   \n",
              "5       Astrology: I am a Capricorn Sun Cap moon and c...   \n",
              "6                                     Should I buy tiago?   \n",
              "7                          How can I be a good geologist?   \n",
              "8                         When do you use シ instead of し?   \n",
              "9       Motorola (company): Can I hack my Charter Moto...   \n",
              "10      Method to find separation of slits using fresn...   \n",
              "11            How do I read and find my YouTube comments?   \n",
              "12                   What can make Physics easy to learn?   \n",
              "13            What was your first sexual experience like?   \n",
              "14      What are the laws to change your status from a...   \n",
              "15      What would a Trump presidency mean for current...   \n",
              "16                           What does manipulation mean?   \n",
              "17      Why do girls want to be friends with the guy t...   \n",
              "18      Why are so many Quora users posting questions ...   \n",
              "19      Which is the best digital marketing institutio...   \n",
              "20                             Why do rockets look white?   \n",
              "21                  What's causing someone to be jealous?   \n",
              "22        What are the questions should not ask on Quora?   \n",
              "23                               How much is 30 kV in HP?   \n",
              "24      What does it mean that every time I look at th...   \n",
              "25      What are some tips on making it through the jo...   \n",
              "26                               What is web application?   \n",
              "27      Does society place too much importance on sports?   \n",
              "28                 What is best way to make money online?   \n",
              "29                 How should I prepare for CA final law?   \n",
              "...                                                   ...   \n",
              "404260                   Which phone is best under 12000?   \n",
              "404261  Who is the overall most popular Game of Throne...   \n",
              "404262          How do you troubleshoot a Toshiba laptop?   \n",
              "404263  How does the burning of fossil fuels contribut...   \n",
              "404264  Is it safe to store an external battery power ...   \n",
              "404265                  How can I gain weight on my body?   \n",
              "404266  What is the green dot next to the phone icon o...   \n",
              "404267  What are the causes of the fall of the Roman E...   \n",
              "404268  Why don't we still do great music like in the ...   \n",
              "404269  How do you diagnose antisocial personality dis...   \n",
              "404270        What is the difference between who and how?   \n",
              "404271  Does Stalin have any grandchildren that are st...   \n",
              "404272  What are the best new car products or inventio...   \n",
              "404273    What happens if you put milk in a coffee maker?   \n",
              "404274  Will the next generation of parenting change o...   \n",
              "404275  In accounting, why do we debit expenses and cr...   \n",
              "404276                         What is copilotsearch.com?   \n",
              "404277                            What does analytics do?   \n",
              "404278          How did you prepare for AIIMS/NEET/AIPMT?   \n",
              "404279  What is the minimum time required to build a f...   \n",
              "404280  What are some outfit ideas to wear to a frat p...   \n",
              "404281  Why is Manaphy childish in Pokémon Ranger and ...   \n",
              "404282        How does a long distance relationship work?   \n",
              "404283  What do you think of the removal of the MagSaf...   \n",
              "404284         What does Jainism say about homosexuality?   \n",
              "404285  How many keywords are there in the Racket prog...   \n",
              "404286          Do you believe there is life after death?   \n",
              "404287                                  What is one coin?   \n",
              "404288  What is the approx annual cost of living while...   \n",
              "404289              What is like to have sex with cousin?   \n",
              "\n",
              "                                                question2  is_duplicate  \n",
              "0       What is the step by step guide to invest in sh...             0  \n",
              "1       What would happen if the Indian government sto...             0  \n",
              "2       How can Internet speed be increased by hacking...             0  \n",
              "3       Find the remainder when [math]23^{24}[/math] i...             0  \n",
              "4                 Which fish would survive in salt water?             0  \n",
              "5       I'm a triple Capricorn (Sun, Moon and ascendan...             1  \n",
              "6       What keeps childern active and far from phone ...             0  \n",
              "7               What should I do to be a great geologist?             1  \n",
              "8                   When do you use \"&\" instead of \"and\"?             0  \n",
              "9       How do I hack Motorola DCX3400 for free internet?             0  \n",
              "10      What are some of the things technicians can te...             0  \n",
              "11                 How can I see all my Youtube comments?             1  \n",
              "12                How can you make physics easy to learn?             1  \n",
              "13                 What was your first sexual experience?             1  \n",
              "14      What are the laws to change your status from a...             0  \n",
              "15      How will a Trump presidency affect the student...             1  \n",
              "16                          What does manipulation means?             1  \n",
              "17               How do guys feel after rejecting a girl?             0  \n",
              "18      Why do people ask Quora questions which can be...             1  \n",
              "19      Which is the best digital marketing institute ...             0  \n",
              "20            Why are rockets and boosters painted white?             1  \n",
              "21       What can I do to avoid being jealous of someone?             0  \n",
              "22                  Which question should I ask on Quora?             0  \n",
              "23      Where can I find a conversion chart for CC to ...             0  \n",
              "24       How many times a day do a clock’s hands overlap?             0  \n",
              "25      What are some tips on making it through the jo...             0  \n",
              "26                 What is the web application framework?             0  \n",
              "27               How do sports contribute to the society?             0  \n",
              "28              What is best way to ask for money online?             0  \n",
              "29      How one should know that he/she completely pre...             1  \n",
              "...                                                   ...           ...  \n",
              "404260           What is the best phone to buy below 15k?             0  \n",
              "404261  Who is the most popular character in the Game ...             1  \n",
              "404262                   How do I reset a Toshiba laptop?             0  \n",
              "404263  Why does CO2 contribute more to global warming...             0  \n",
              "404264         How do I make a safe and cheap power bank?             0  \n",
              "404265                  What should I eat to gain weight?             1  \n",
              "404266  My boyfriend says he deleted his Facebook Mess...             0  \n",
              "404267  What were the most important causes and effect...             1  \n",
              "404268       Should I raise my young child on 80's music?             0  \n",
              "404269  What Does It Feel Like to have antisocial pers...             0  \n",
              "404270      What is the difference between \"&\" and \"and\"?             0  \n",
              "404271  What was Joseph Stalin's 5 year plan? How did ...             0  \n",
              "404272  What are some mind-blowing vehicles tools that...             1  \n",
              "404273  What would happen if I put milk instead of wat...             1  \n",
              "404274  What kind of parents will the next generation ...             1  \n",
              "404275  What is a utilities expense in accounting? How...             0  \n",
              "404276                           What is ContenVania.com?             0  \n",
              "404277                   What are analytical people like?             0  \n",
              "404278  How did you prepare for the AIIMS UG entrance ...             0  \n",
              "404279  What is a cheaper and quicker way to build an ...             0  \n",
              "404280  What are some outfit ideas wear to a frat them...             1  \n",
              "404281  Why is Manaphy annoying in Pokemon ranger and ...             1  \n",
              "404282    How are long distance relationships maintained?             1  \n",
              "404283  What will the CPU upgrade to the 2016 Apple Ma...             0  \n",
              "404284  What does Jainism say about Gays and Homosexua...             1  \n",
              "404285  How many keywords are there in PERL Programmin...             0  \n",
              "404286         Is it true that there is life after death?             1  \n",
              "404287                                  What's this coin?             0  \n",
              "404288  I am having little hairfall problem but I want...             0  \n",
              "404289      What is it like to have sex with your cousin?             0  \n",
              "\n",
              "[404290 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "p13HdkzWKtKe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "I will teach on these texts Word2vec from gensim.\n",
        "\n",
        "First, combine all the texts.\n",
        "\n",
        "First, combine all the texts."
      ]
    },
    {
      "metadata": {
        "id": "Mchv4fS_21OX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "9251e0cc-e81d-4fe8-f312-cb6103537b0f"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "quora_data.question1 = quora_data.question1.replace(np.nan, '', regex=True)\n",
        "quora_data.question2 = quora_data.question2.replace(np.nan, '', regex=True)\n",
        "\n",
        "texts = list(pd.concat([quora_data.question1, quora_data.question2]).unique())\n",
        "texts[:10]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['What is the step by step guide to invest in share market in india?',\n",
              " 'What is the story of Kohinoor (Koh-i-Noor) Diamond?',\n",
              " 'How can I increase the speed of my internet connection while using a VPN?',\n",
              " 'Why am I mentally very lonely? How can I solve it?',\n",
              " 'Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?',\n",
              " 'Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?',\n",
              " 'Should I buy tiago?',\n",
              " 'How can I be a good geologist?',\n",
              " 'When do you use シ instead of し?',\n",
              " 'Motorola (company): Can I hack my Charter Motorolla DCX3400?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "-hZMFAmvK5b7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "For tokenization, the easiest way is to use `nltk` (it is faster than` spacy`, but may be worse in some cases)."
      ]
    },
    {
      "metadata": {
        "id": "LTxolf8nLM-n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "5fe74c68-c247-4db3-d5ea-fd8601309fa3"
      },
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "word_tokenize(texts[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['What',\n",
              " 'is',\n",
              " 'the',\n",
              " 'step',\n",
              " 'by',\n",
              " 'step',\n",
              " 'guide',\n",
              " 'to',\n",
              " 'invest',\n",
              " 'in',\n",
              " 'share',\n",
              " 'market',\n",
              " 'in',\n",
              " 'india',\n",
              " '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "fuJceE4JLRxK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Task Set all texts to lower case and tokenize them."
      ]
    },
    {
      "metadata": {
        "id": "a7XbnSdt4REg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "5752e7f7-ee71-49f8-be74-e54d25ebe503"
      },
      "cell_type": "code",
      "source": [
        "tokenized_texts = 'do smth'\n",
        "\n",
        "assert all(isinstance(row, (list, tuple)) for row in tokenized_texts), \\\n",
        "    sent = [word for line in f for word in line.lower().split()]\n",
        "assert all(all(isinstance(tok, str) for tok in row) for row in tokenized_texts), \\\n",
        "    sent = [word for line in f for word in line.lower().split()]\n",
        "\n",
        "is_latin = lambda tok: all('a' <= x.lower() <= 'z' for x in tok)\n",
        "assert all(not is_latin(token) or token.islower() for tokens in tokenized_texts for token in tokens),\\\n",
        "    sent = [word for line in f for word in line.lower().split()]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-3711ed5bf020>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    assert all(isinstance(row, (list, tuple)) for row in tokenized_texts),     sent = [word for line in f for word in line.lower().split()]\u001b[0m\n\u001b[0m                                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "irl7RotC5C_B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b86ffd02-f3b4-4700-c5e6-ea1e453c21f3"
      },
      "cell_type": "code",
      "source": [
        "print([' '.join(row) for row in tokenized_texts[:2]])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['d', 'o']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9kj4dC3iLdwH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let's practice a small model on the received texts:"
      ]
    },
    {
      "metadata": {
        "id": "9GNuiLio8M25",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 931
        },
        "outputId": "69f96777-dbac-431f-c7f9-53f748a96a12"
      },
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "model = Word2Vec(tokenized_texts, \n",
        "                 size=32,      # embedding vector size\n",
        "                 min_count=5,  # consider words that occured at least 5 times\n",
        "                 window=5).wv  # define context as a 5-word window around the target word"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e37961066ea9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                  \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;31m# embedding vector size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                  \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# consider words that occured at least 5 times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                  window=5).wv  # define context as a 5-word window around the target word\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, iter, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, max_final_vocab)\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbow_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcbow_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m             fast_version=FAST_VERSION)\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m     def _do_train_epoch(self, corpus_file, thread_id, offset, cython_vocab, thread_private_mem, cur_epoch,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, workers, vector_size, epochs, callbacks, batch_words, trim_rule, sg, alpha, window, seed, hs, negative, ns_exponent, cbow_mean, min_alpha, compute_loss, fast_version, **kwargs)\u001b[0m\n\u001b[1;32m    761\u001b[0m                 \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m                 \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m                 end_alpha=self.min_alpha, compute_loss=compute_loss)\n\u001b[0m\u001b[1;32m    764\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrim_rule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks)\u001b[0m\n\u001b[1;32m    908\u001b[0m             \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m             queue_factor=queue_factor, report_delay=report_delay, compute_loss=compute_loss, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_sentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueue_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_job_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m             total_words=total_words, **kwargs)\n\u001b[0m\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_check_training_sanity\u001b[0;34m(self, epochs, total_examples, total_words, **kwargs)\u001b[0m\n\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# should be set by `build_vocab`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1187\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"you must first build vocabulary before training the model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"you must initialize vectors before training the model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: you must first build vocabulary before training the model"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "JclToDJMNwTy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## We study the resulting model"
      ]
    },
    {
      "metadata": {
        "id": "JBVR2kY7LkCs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Hooray, now you can do the same that was on `rusvectores`.\n",
        "\n",
        "Get vector for word:"
      ]
    },
    {
      "metadata": {
        "id": "Jk6Fgraj-j3c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "a17cb768-06dc-4d40-a2e3-7b4d9b8ae05a"
      },
      "cell_type": "code",
      "source": [
        "model.get_vector('anything')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-5859607387a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'anything'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "qHKRy7HyLuxH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Find the closest words:"
      ]
    },
    {
      "metadata": {
        "id": "toyNzyTB-p70",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "48896722-c7cb-44f9-94e3-c2b7d9a0c268"
      },
      "cell_type": "code",
      "source": [
        "model.most_similar('bread')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-e3e4858a0e0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bread'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "A510z5gTL00E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Or even like this:"
      ]
    },
    {
      "metadata": {
        "id": "j2A_DF5E-ucq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "e852e328-1408-4212-c492-4425710d3a5a"
      },
      "cell_type": "code",
      "source": [
        "model.most_similar(positive=['coder', 'money'], negative=['brain'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-b3e6421c4221>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'coder'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'money'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'brain'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "H-_uKG4vNIJv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And so of course:"
      ]
    },
    {
      "metadata": {
        "id": "l_mzQgi4L474",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "b2848c16-a412-4c8f-d107-3aa57cb8946b"
      },
      "cell_type": "code",
      "source": [
        "model.most_similar([model.get_vector('politician') - model.get_vector('power') + model.get_vector('honesty')])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-18b85b990dd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'politician'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'power'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'honesty'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "y5BAEyMyL2kx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "** Task ** Look for analogies yourself."
      ]
    },
    {
      "metadata": {
        "id": "1FYuh4DKN1Fd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Visualize the model"
      ]
    },
    {
      "metadata": {
        "id": "OdT0eIEiN4Ja",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let's look at the projections of the first thousand of the most frequent words."
      ]
    },
    {
      "metadata": {
        "id": "d1e9yS0zBr6j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "26a02a47-16b2-408e-9a44-cd4d5569f542"
      },
      "cell_type": "code",
      "source": [
        "words = sorted(model.vocab.keys(), \n",
        "               key=lambda word: model.vocab[word].count,\n",
        "               reverse=True)[:1000]\n",
        "\n",
        "print(words[::100])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-25f27b64f696>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m words = sorted(model.vocab.keys(), \n\u001b[0m\u001b[1;32m      2\u001b[0m                \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                reverse=True)[:1000]\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "0Yk5pgMXOESS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "** Task ** Build a matrix of embeddingings of these words:"
      ]
    },
    {
      "metadata": {
        "id": "kQu724f2CAh0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "aefc24f8-255c-4975-c45d-525f8a9ae562"
      },
      "cell_type": "code",
      "source": [
        "word_vectors = model.vectors[[model.vocab[word].index for word in words]]\n",
        "\n",
        "assert isinstance(word_vectors, np.ndarray)\n",
        "assert word_vectors.shape == (len(words), model.vectors.shape[1])\n",
        "assert np.isfinite(word_vectors).all()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-5c0c524055b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mword_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "f7cgxin-OTvK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### PCA\n",
        "\n",
        "The simplest linear dimension reduction method is __P__rincipial __C__omponent __A__nalysis.\n",
        "\n",
        "The PCA is looking for axes on which the data will have the largest scatter when projected.\n",
        "\n",
        "! [pca] (https://i.stack.imgur.com/Q7HIP.gif)\n",
        "* From [https://stats.stackexchange.com/a/140579 ((https://stats.stackexchange.com/a/140579) ()\n",
        "\n",
        "As a result, you can take the projections onto the first few components - and save as much information as possible, reducing the dimension.\n",
        "\n",
        "Beautiful visualizations can be found [here] (http://setosa.io/ev/principal-component-analysis/).\n",
        "\n",
        "** Task ** Use the PCA from sklearn, and then center and normalize the result."
      ]
    },
    {
      "metadata": {
        "id": "V0fQKZw2Css4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "eb0d12c9-66f5-401d-9e33-72993d2bd372"
      },
      "cell_type": "code",
      "source": [
        "<imports>\n",
        "\n",
        "def get_pca_projection(word_vectors):\n",
        "    <code>"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-7a551d470f1f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <imports>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "a_9VtLl9CviW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "b89dd05a-ae53-44eb-b1d8-792cd878019b"
      },
      "cell_type": "code",
      "source": [
        "word_vectors_pca = get_pca_projection(word_vectors)\n",
        "\n",
        "assert word_vectors_pca.shape == (len(word_vectors), 2), \"there must be a 2d vector for each word\"\n",
        "assert max(abs(word_vectors_pca.mean(0))) < 1e-5, \"points must be zero-centered\"\n",
        "assert max(abs(1 - word_vectors_pca.std(0))) < 1e-5, \"points must have unit variance\""
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-ff81fc882653>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword_vectors_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pca_projection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mword_vectors_pca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"there must be a 2d vector for each word\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_vectors_pca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"points must be zero-centered\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mword_vectors_pca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"points must have unit variance\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_pca_projection' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "jGyvhrk7Rlyt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Visualize what happened:"
      ]
    },
    {
      "metadata": {
        "id": "1U58YxF3Cx0W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import bokeh.models as bm, bokeh.plotting as pl\n",
        "from bokeh.io import output_notebook\n",
        "\n",
        "def draw_vectors(x, y, radius=10, alpha=0.25, color='blue',\n",
        "                 width=600, height=400, show=True, **kwargs):\n",
        "    \"\"\" draws an interactive plot for data points with auxilirary info on hover \"\"\"\n",
        "    output_notebook()\n",
        "    \n",
        "    if isinstance(color, str): \n",
        "        color = [color] * len(x)\n",
        "    data_source = bm.ColumnDataSource({ 'x' : x, 'y' : y, 'color': color, **kwargs })\n",
        "\n",
        "    fig = pl.figure(active_scroll='wheel_zoom', width=width, height=height)\n",
        "    fig.scatter('x', 'y', size=radius, color='color', alpha=alpha, source=data_source)\n",
        "\n",
        "    fig.add_tools(bm.HoverTool(tooltips=[(key, \"@\" + key) for key in kwargs.keys()]))\n",
        "    if show: \n",
        "        pl.show(fig)\n",
        "    return fig"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qBljy2hCC1qX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "584f6f4a-0eae-4afa-cb17-6a0f675a5cf8"
      },
      "cell_type": "code",
      "source": [
        "draw_vectors(word_vectors_pca[:, 0], word_vectors_pca[:, 1], token=words)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-c2245f44310e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdraw_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_vectors_pca\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_vectors_pca\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'word_vectors_pca' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "VOIU8uXnSItf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### TSNE\n",
        "\n",
        "A more interesting and complex (non-linear) method for visualizing high-dimensional spaces is TSNE. You can look at it in detail [here] (https://distill.pub/2016/misread-tsne/) (even more beautiful pictures!).\n",
        "\n",
        "** Task ** As with PCA, use TSNE from sklearn and normalize + center the result."
      ]
    },
    {
      "metadata": {
        "id": "F-nlN4_aDF9G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "719184e2-2a92-42d7-a355-660122e9c7d6"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def get_tsne_projection(word_vectors):\n",
        "    <your code>"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-9fe7abcd07c5>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    <your code>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "D_YFR_rYDK2n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "f2114bdd-a202-4a81-b89f-e5c9247e01bf"
      },
      "cell_type": "code",
      "source": [
        "word_tsne = get_tsne_projection(word_vectors)\n",
        "draw_vectors(word_tsne[:, 0], word_tsne[:, 1], color='green', token=words)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-c9bc809f0271>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword_tsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tsne_projection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdraw_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tsne\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_tsne\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'green'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_tsne_projection' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "sz6uHYMbSjuE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Embedded phrases"
      ]
    },
    {
      "metadata": {
        "id": "L4GEypE4SokX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now for tests it will be useful to use fixed embeddings. Let's load already trained model.\n",
        "(see which models and models are available at all, by calling `api.info ()`)"
      ]
    },
    {
      "metadata": {
        "id": "GUDRtumXXF3S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e128d1e0-416c-4e00-e58b-14445e7c9db3"
      },
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "model = api.load('glove-twitter-100')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==============================================----] 93.7% 362.6/387.1MB downloaded"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eypMhlOSXFWN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A simple and cheap way to calculate embedding of a phrase, when there are word embeddings - to average.\n",
        "\n",
        "So let's do this: tokenize and lower-case the phrase, average the embeddingings of the words for which they are counted.\n",
        "\n",
        "** Task ** Write a function to count phrase embedding."
      ]
    },
    {
      "metadata": {
        "id": "F76HGRGDEPVq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "87c8caf1-5c31-451c-d7f4-0dd1738c2619"
      },
      "cell_type": "code",
      "source": [
        "def get_phrase_embedding(model, phrase):    \n",
        "    vector = np.zeros([model.vector_size], dtype='float32')\n",
        "    \n",
        "    <write me>\n",
        "    \n",
        "    return vector"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-d148dfee9488>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    <write me>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "i12XsqnIXfko",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "30f366b2-bb69-44fe-8c24-cc61140f439a"
      },
      "cell_type": "code",
      "source": [
        "vector = get_phrase_embedding(model, \"I'm very sure. This never happened to me before...\")\n",
        "\n",
        "assert np.allclose(vector[::10],\n",
        "                   np.array([ 0.30757686, -0.05861897,  0.143751  , -0.11104885, -0.96929336,\n",
        "                             -0.21928601,  0.21652265,  0.14978765,  1.4842536 ,  0.017826  ],\n",
        "                              dtype=np.float32))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-f07f3987ad07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_phrase_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I'm very sure. This never happened to me before...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m assert np.allclose(vector[::10],\n\u001b[1;32m      4\u001b[0m                    np.array([ 0.30757686, -0.05861897,  0.143751  , -0.11104885, -0.96929336,\n\u001b[1;32m      5\u001b[0m                              -0.21928601,  0.21652265,  0.14978765,  1.4842536 ,  0.017826  ],\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_phrase_embedding' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Yl2nBZG0WAUx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Calculate the vector of all phrases."
      ]
    },
    {
      "metadata": {
        "id": "40LezFEJFwv3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "dcf64245-c441-4d60-c70c-1e94154addcb"
      },
      "cell_type": "code",
      "source": [
        "text_vectors = np.array([get_phrase_embedding(model, phrase) for phrase in tokenized_texts])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-ef6fef06ce40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_phrase_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mphrase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized_texts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-ef6fef06ce40>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_phrase_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mphrase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized_texts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'get_phrase_embedding' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "nBj8XMZvWFTv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "And learn to look for coming!\n",
        "\n",
        "** Assignment ** Find the k nearest questions by line."
      ]
    },
    {
      "metadata": {
        "id": "fjw7kTQ-FP11",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "6b9c05f6-9f04-4650-d53f-28a1cb0a6da8"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def find_nearest(model, text_vectors, texts, query, k=10):\n",
        "    <write me, please>"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-4e552cdc6bd2>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    <write me, please>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "c2yK0twNGWaQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "9d211d0f-a49d-4a89-aec1-feaad00292b5"
      },
      "cell_type": "code",
      "source": [
        "results = find_nearest(model, text_vectors, texts, query=\"How do i enter the matrix?\", k=10)\n",
        "\n",
        "print('\\n'.join(results))\n",
        "\n",
        "assert len(results) == 10 and isinstance(results[0], str)\n",
        "assert results[1] == 'How do I get to the dark web?'\n",
        "assert results[4] == 'What can I do to save the world?'"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-0ecdaf65e021>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_nearest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"How do i enter the matrix?\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'find_nearest' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "AutTfxbDGhku",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "6576f2e2-39fc-4569-ead8-e207029b5d5c"
      },
      "cell_type": "code",
      "source": [
        "find_nearest(model, text_vectors, texts, query=\"How does Trump?\", k=10)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-e2b05e9c1d98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_nearest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"How does Trump?\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'find_nearest' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "47Ff7heKGiGV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "b9d3f306-f10e-41a0-d2a4-974634a2427a"
      },
      "cell_type": "code",
      "source": [
        "find_nearest(model, text_vectors, texts, query=\"Why don't i ask a question myself?\", k=10)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-3df776ed1de6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_nearest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Why don't i ask a question myself?\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'find_nearest' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "5BhDEF11ZnTY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Getting a classification"
      ]
    },
    {
      "metadata": {
        "id": "2D_LEV8cm0z3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Bag-of-words"
      ]
    },
    {
      "metadata": {
        "id": "jGge73gDid99",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Task ** Let's collect tokens for the beginning."
      ]
    },
    {
      "metadata": {
        "id": "FJTjqdgiih7O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenized_question1 = ...\n",
        "tokenized_question2 = ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0VBcipE7Ztkc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "** Task ** Calculate cosine proximity between questions.\n",
        "\n",
        "The easiest way is to implement the function of its calculation by hand:\n",
        "$$\\text{cosine_similarity}(x, y) = \\frac{x^{T} y}{||x||\\cdot ||y||}$$"
      ]
    },
    {
      "metadata": {
        "id": "ItJLR_ENHGtI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "1ee4c04f-bb5e-48c2-b134-6d6fcad87afa"
      },
      "cell_type": "code",
      "source": [
        "<do smth>\n",
        "\n",
        "cosine_similarities = <and calc the result>"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-31-ac6103a225a9>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <do smth>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "NgCVueJ4Z3DQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "** Task ** Calculate cosine proximity between questions.\n",
        "\n",
        "The easiest way is to implement the function of its calculation by hand:"
      ]
    },
    {
      "metadata": {
        "id": "41hRIb-KSA3F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "2059e6ea-c665-4d48-e24e-f9f0ecf22dd1"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def accuracy(cosine_similarities, threshold):\n",
        "    return <accuracy>\n",
        "\n",
        "thresholds = np.linspace(0, 1, 100, endpoint=False)\n",
        "plt.plot(thresholds, [accuracy(cosine_similarities, th) for th in thresholds])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-32-52e7fec875ef>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    return <accuracy>\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "kOxJSE38msmX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "And run the optimization:"
      ]
    },
    {
      "metadata": {
        "id": "R3LVCJwqSgZz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "977ba184-58bc-4176-a162-0b21d44b42c6"
      },
      "cell_type": "code",
      "source": [
        "from scipy.optimize import minimize_scalar\n",
        "\n",
        "res = minimize_scalar(lambda x: -accuracy(cosine_similarities, x), bounds=(0.5, 0.99), method='bounded')\n",
        "best_threshold = res.x\n",
        "print('Threshold = {:.5f}, Accuracy = {:.2%}'.format(best_threshold, accuracy(cosine_similarities, best_threshold)))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-d64534465cc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mminimize_scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimize_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine_similarities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bounded'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mbest_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Threshold = {:.5f}, Accuracy = {:.2%}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine_similarities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize_scalar\u001b[0;34m(fun, bracket, bounds, args, method, tol, options)\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'disp'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_scalar_bounded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'golden'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_scalar_golden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbracket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_minimize_scalar_bounded\u001b[0;34m(func, bounds, args, xatol, maxiter, disp, **unknown_options)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     \u001b[0mrat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1740\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1741\u001b[0;31m     \u001b[0mfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1742\u001b[0m     \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1743\u001b[0m     \u001b[0mfmin_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-d64534465cc6>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mminimize_scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimize_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine_similarities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bounded'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mbest_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Threshold = {:.5f}, Accuracy = {:.2%}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine_similarities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'accuracy' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "H8yFlaffm34A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Tf-idf weights"
      ]
    },
    {
      "metadata": {
        "id": "-cpeSa-4m64H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Instead of stupidly averaging the vectors, you can average them based on the weights - the familiar tf-idf will help in this.\n",
        "\n",
        "** Task ** Calculate weighted vector of questions. Use `TfidfVectorizer`\n",
        "\n",
        "`TfidfVectorizer` returns the matrix` (samples_count, words_count) `. And our embeddings have the dimension `(words_count, embedding_dim)`. So you can just multiply them. Then each phrase - the sequence of words $ w_1, \\ ldots, w_k $ - is transformed into the vector $ \\ sum_i \\ text {idf} (w_i) \\ cdot \\ text {embedding} (w_i) $. This vector should probably be normalized to the number of words $ k $.\n",
        "\n",
        "** Task ** In addition to tf-idf, you can add filtering of stop words and punctuation.\n",
        "Stop words can be taken from `nltk`:\n",
        "```python\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "UoYjVExHd_OC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "03918532-0845-4f68-e1a7-d3151c225767"
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "\n",
        "<calculate tf-idf weighted vectors>"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-34-740c964eb05f>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    <calculate tf-idf weighted vectors>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "34Di8jXxoBxg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let's see what happens after filtering and vectoring:"
      ]
    },
    {
      "metadata": {
        "id": "k52NtVJKf1Wl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "faa1f4fc-8ac1-4bd4-bc11-c21c6abe6c52"
      },
      "cell_type": "code",
      "source": [
        "for col in tfidf_question1[0].tocoo().col:\n",
        "    print(model.index2word[col], end=' ')\n",
        "\n",
        "print('\\n' + ' '.join(tokenized_question1[0]))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-47324aa4f683>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtfidf_question1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocoo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex2word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_question1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tfidf_question1' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "3fMqY5tOoL9r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "** Task ** Calculate quality with new vectors."
      ]
    },
    {
      "metadata": {
        "id": "Chf2qy7uhbPF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "90c743b8-13eb-411f-8d4d-c47ee4ea82c7"
      },
      "cell_type": "code",
      "source": [
        "cosine_similarities = <calc it somehow>\n",
        "\n",
        "res = minimize_scalar(lambda x: -accuracy(cosine_similarities, x), bounds=(0.8, 0.99), method='bounded')\n",
        "best_threshold = res.x\n",
        "print('Threshold = {:.5f}, Accuracy = {:.2%}'.format(best_threshold, accuracy(cosine_similarities, best_threshold)))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-36-705cfd009ac4>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    cosine_similarities = <calc it somehow>\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "qXi24B78sbsg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Let's look inside learning word embeddings"
      ]
    },
    {
      "metadata": {
        "id": "6GSDgSXfswp7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "The key idea is that a word can be defined by the context in which it occurs:\n",
        "! [contexts] (https://image.ibb.co/mnQ2uz/2018_09_17_21_07_08.png)\n",
        "* From [cs224n, Lecture 2] (http://web.stanford.edu/class/cs224n/lectures/lecture2.pdf) *\n",
        "\n",
        "Watch how everything learns, we will be here: [https://ronxin.github.io/wevi/[ (http: //ronxin.github.io/wevi/)."
      ]
    },
    {
      "metadata": {
        "id": "xvqrFUS6vVhh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Sewing down a word for machine translation!"
      ]
    },
    {
      "metadata": {
        "id": "1CXcr-ypzGXg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "45439bff-a945-4679-ec0a-e1d6e6ec7fd4"
      },
      "cell_type": "code",
      "source": [
        "!wget -O ukr_rus.train.txt -qq --no-check-certificate \"https://drive.google.com/uc?export=download&id=1vAK0SWXUqei4zTimMvIhH3ufGPsbnC_O\"\n",
        "!wget -O ukr_rus.test.txt -qq --no-check-certificate \"https://drive.google.com/uc?export=download&id=1W9R2F8OeKHXruo2sicZ6FgBJUTJc8Us_\"\n",
        "!wget -O fairy_tale.txt -qq --no-check-certificate \"https://drive.google.com/uc?export=download&id=1sq8zSroFeg_afw-60OmY8RATdu_T1tej\"\n",
        "\n",
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "downloaded = drive.CreateFile({'id': '1d7OXuil646jUeDS1JNhP9XWlZogv6rbu'})\n",
        "downloaded.GetContentFile('cc.ru.300.vec.zip')\n",
        "\n",
        "downloaded = drive.CreateFile({'id': '1yAqwqgUHtMSfGS99WLGe5unSCyIXfIxi'})\n",
        "downloaded.GetContentFile('cc.uk.300.vec.zip')\n",
        "\n",
        "!unzip cc.ru.300.vec.zip\n",
        "!unzip cc.uk.300.vec.zip"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K    1% |▎                               | 10kB 17.2MB/s eta 0:00:01\r\u001b[K    2% |▋                               | 20kB 1.8MB/s eta 0:00:01\r\u001b[K    3% |█                               | 30kB 2.6MB/s eta 0:00:01\r\u001b[K    4% |█▎                              | 40kB 1.7MB/s eta 0:00:01\r\u001b[K    5% |█▋                              | 51kB 2.1MB/s eta 0:00:01\r\u001b[K    6% |██                              | 61kB 2.5MB/s eta 0:00:01\r\u001b[K    7% |██▎                             | 71kB 2.2MB/s eta 0:00:01\r\u001b[K    8% |██▋                             | 81kB 2.4MB/s eta 0:00:01\r\u001b[K    9% |███                             | 92kB 2.7MB/s eta 0:00:01\r\u001b[K    10% |███▎                            | 102kB 2.8MB/s eta 0:00:01\r\u001b[K    11% |███▋                            | 112kB 2.8MB/s eta 0:00:01\r\u001b[K    12% |████                            | 122kB 4.0MB/s eta 0:00:01\r\u001b[K    13% |████▎                           | 133kB 4.1MB/s eta 0:00:01\r\u001b[K    14% |████▋                           | 143kB 7.7MB/s eta 0:00:01\r\u001b[K    15% |█████                           | 153kB 4.8MB/s eta 0:00:01\r\u001b[K    16% |█████▎                          | 163kB 4.7MB/s eta 0:00:01\r\u001b[K    17% |█████▋                          | 174kB 7.6MB/s eta 0:00:01\r\u001b[K    18% |██████                          | 184kB 7.7MB/s eta 0:00:01\r\u001b[K    19% |██████▎                         | 194kB 7.7MB/s eta 0:00:01\r\u001b[K    20% |██████▋                         | 204kB 8.0MB/s eta 0:00:01\r\u001b[K    21% |███████                         | 215kB 8.1MB/s eta 0:00:01\r\u001b[K    22% |███████▎                        | 225kB 8.1MB/s eta 0:00:01\r\u001b[K    23% |███████▋                        | 235kB 8.2MB/s eta 0:00:01\r\u001b[K    24% |████████                        | 245kB 8.2MB/s eta 0:00:01\r\u001b[K    25% |████████▎                       | 256kB 23.7MB/s eta 0:00:01\r\u001b[K    26% |████████▋                       | 266kB 23.5MB/s eta 0:00:01\r\u001b[K    27% |█████████                       | 276kB 25.8MB/s eta 0:00:01\r\u001b[K    29% |█████████▎                      | 286kB 26.3MB/s eta 0:00:01\r\u001b[K    30% |█████████▋                      | 296kB 9.3MB/s eta 0:00:01\r\u001b[K    31% |██████████                      | 307kB 10.9MB/s eta 0:00:01\r\u001b[K    32% |██████████▎                     | 317kB 11.0MB/s eta 0:00:01\r\u001b[K    33% |██████████▋                     | 327kB 10.9MB/s eta 0:00:01\r\u001b[K    34% |███████████                     | 337kB 11.0MB/s eta 0:00:01\r\u001b[K    35% |███████████▎                    | 348kB 10.5MB/s eta 0:00:01\r\u001b[K    36% |███████████▋                    | 358kB 10.5MB/s eta 0:00:01\r\u001b[K    37% |████████████                    | 368kB 10.9MB/s eta 0:00:01\r\u001b[K    38% |████████████▎                   | 378kB 10.9MB/s eta 0:00:01\r\u001b[K    39% |████████████▋                   | 389kB 11.0MB/s eta 0:00:01\r\u001b[K    40% |█████████████                   | 399kB 47.7MB/s eta 0:00:01\r\u001b[K    41% |█████████████▎                  | 409kB 50.4MB/s eta 0:00:01\r\u001b[K    42% |█████████████▋                  | 419kB 53.2MB/s eta 0:00:01\r\u001b[K    43% |██████████████                  | 430kB 40.1MB/s eta 0:00:01\r\u001b[K    44% |██████████████▎                 | 440kB 38.9MB/s eta 0:00:01\r\u001b[K    45% |██████████████▋                 | 450kB 38.9MB/s eta 0:00:01\r\u001b[K    46% |███████████████                 | 460kB 37.5MB/s eta 0:00:01\r\u001b[K    47% |███████████████▎                | 471kB 37.5MB/s eta 0:00:01\r\u001b[K    48% |███████████████▋                | 481kB 37.3MB/s eta 0:00:01\r\u001b[K    49% |████████████████                | 491kB 37.1MB/s eta 0:00:01\r\u001b[K    50% |████████████████▎               | 501kB 37.3MB/s eta 0:00:01\r\u001b[K    51% |████████████████▋               | 512kB 34.0MB/s eta 0:00:01\r\u001b[K    52% |█████████████████               | 522kB 33.7MB/s eta 0:00:01\r\u001b[K    53% |█████████████████▎              | 532kB 43.4MB/s eta 0:00:01\r\u001b[K    54% |█████████████████▋              | 542kB 44.9MB/s eta 0:00:01\r\u001b[K    55% |██████████████████              | 552kB 55.9MB/s eta 0:00:01\r\u001b[K    57% |██████████████████▎             | 563kB 60.2MB/s eta 0:00:01\r\u001b[K    58% |██████████████████▋             | 573kB 60.6MB/s eta 0:00:01\r\u001b[K    59% |███████████████████             | 583kB 61.5MB/s eta 0:00:01\r\u001b[K    60% |███████████████████▎            | 593kB 62.0MB/s eta 0:00:01\r\u001b[K    61% |███████████████████▋            | 604kB 62.3MB/s eta 0:00:01\r\u001b[K    62% |████████████████████            | 614kB 64.8MB/s eta 0:00:01\r\u001b[K    63% |████████████████████▎           | 624kB 14.3MB/s eta 0:00:01\r\u001b[K    64% |████████████████████▋           | 634kB 14.0MB/s eta 0:00:01\r\u001b[K    65% |█████████████████████           | 645kB 13.8MB/s eta 0:00:01\r\u001b[K    66% |█████████████████████▎          | 655kB 13.8MB/s eta 0:00:01\r\u001b[K    67% |█████████████████████▋          | 665kB 12.5MB/s eta 0:00:01\r\u001b[K    68% |██████████████████████          | 675kB 12.5MB/s eta 0:00:01\r\u001b[K    69% |██████████████████████▎         | 686kB 12.5MB/s eta 0:00:01\r\u001b[K    70% |██████████████████████▋         | 696kB 12.4MB/s eta 0:00:01\r\u001b[K    71% |███████████████████████         | 706kB 12.4MB/s eta 0:00:01\r\u001b[K    72% |███████████████████████▎        | 716kB 12.6MB/s eta 0:00:01\r\u001b[K    73% |███████████████████████▋        | 727kB 40.0MB/s eta 0:00:01\r\u001b[K    74% |████████████████████████        | 737kB 40.4MB/s eta 0:00:01\r\u001b[K    75% |████████████████████████▎       | 747kB 40.3MB/s eta 0:00:01\r\u001b[K    76% |████████████████████████▋       | 757kB 40.0MB/s eta 0:00:01\r\u001b[K    77% |████████████████████████▉       | 768kB 55.5MB/s eta 0:00:01\r\u001b[K    78% |█████████████████████████▏      | 778kB 57.2MB/s eta 0:00:01\r\u001b[K    79% |█████████████████████████▌      | 788kB 56.4MB/s eta 0:00:01\r\u001b[K    80% |█████████████████████████▉      | 798kB 58.0MB/s eta 0:00:01\r\u001b[K    81% |██████████████████████████▏     | 808kB 56.4MB/s eta 0:00:01\r\u001b[K    82% |██████████████████████████▌     | 819kB 56.6MB/s eta 0:00:01\r\u001b[K    83% |██████████████████████████▉     | 829kB 57.7MB/s eta 0:00:01\r\u001b[K    85% |███████████████████████████▏    | 839kB 62.2MB/s eta 0:00:01\r\u001b[K    86% |███████████████████████████▌    | 849kB 67.1MB/s eta 0:00:01\r\u001b[K    87% |███████████████████████████▉    | 860kB 52.4MB/s eta 0:00:01\r\u001b[K    88% |████████████████████████████▏   | 870kB 51.5MB/s eta 0:00:01\r\u001b[K    89% |████████████████████████████▌   | 880kB 51.9MB/s eta 0:00:01\r\u001b[K    90% |████████████████████████████▉   | 890kB 52.9MB/s eta 0:00:01\r\u001b[K    91% |█████████████████████████████▏  | 901kB 52.7MB/s eta 0:00:01\r\u001b[K    92% |█████████████████████████████▌  | 911kB 54.3MB/s eta 0:00:01\r\u001b[K    93% |█████████████████████████████▉  | 921kB 55.3MB/s eta 0:00:01\r\u001b[K    94% |██████████████████████████████▏ | 931kB 56.1MB/s eta 0:00:01\r\u001b[K    95% |██████████████████████████████▌ | 942kB 55.4MB/s eta 0:00:01\r\u001b[K    96% |██████████████████████████████▉ | 952kB 55.3MB/s eta 0:00:01\r\u001b[K    97% |███████████████████████████████▏| 962kB 76.1MB/s eta 0:00:01\r\u001b[K    98% |███████████████████████████████▌| 972kB 78.7MB/s eta 0:00:01\r\u001b[K    99% |███████████████████████████████▉| 983kB 78.2MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 993kB 18.6MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hArchive:  cc.ru.300.vec.zip\n",
            "  inflating: cc.ru.300.vec           \n",
            "Archive:  cc.uk.300.vec.zip\n",
            "  inflating: cc.uk.300.vec           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7RqUeOXxws8y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's write a simple implementation of the machine translation model.\n",
        "\n",
        "The idea is based on the article [Word Translation Without Parallel Data] (https://arxiv.org/pdf/1710.04087.pdf). The authors of the repository still have a lot of interesting things: [https://github.com/facebookresearch/MUSE_ ((https://github.com/facebookresearch/MUSE).\n",
        "\n",
        "And we will translate from Ukrainian to Russian.\n",
        "\n",
        "! [] (https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/resources/blue_cat_blue_whale.png)\n",
        "* blue kit * vs. * blue whale *"
      ]
    },
    {
      "metadata": {
        "id": "jjPj9FTRry0U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "ru_emb = KeyedVectors.load_word2vec_format(\"cc.ru.300.vec\")\n",
        "uk_emb = KeyedVectors.load_word2vec_format(\"cc.uk.300.vec\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7rGx4TXWFJ65",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let's look at a couple of serpeni-august (being a translation)"
      ]
    },
    {
      "metadata": {
        "id": "FkHer36xyh4n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "103a60a1-28a1-4932-eb4b-f62e0b3e29cf"
      },
      "cell_type": "code",
      "source": [
        "ru_emb.most_similar([ru_emb[\"август\"]])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('август', 1.0),\n",
              " ('июль', 0.9383153915405273),\n",
              " ('сентябрь', 0.9240028858184814),\n",
              " ('июнь', 0.9222575426101685),\n",
              " ('октябрь', 0.9095538854598999),\n",
              " ('ноябрь', 0.8930036425590515),\n",
              " ('апрель', 0.8729087114334106),\n",
              " ('декабрь', 0.8652557730674744),\n",
              " ('март', 0.8545796275138855),\n",
              " ('февраль', 0.8401416540145874)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "1RSDixWvylEP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "dcd3d388-e229-4865-8922-7ed70c2050fa"
      },
      "cell_type": "code",
      "source": [
        "uk_emb.most_similar([uk_emb[\"серпень\"]])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('серпень', 0.9999999403953552),\n",
              " ('липень', 0.9096440076828003),\n",
              " ('вересень', 0.901697039604187),\n",
              " ('червень', 0.8992519378662109),\n",
              " ('жовтень', 0.8810408711433411),\n",
              " ('листопад', 0.8787633776664734),\n",
              " ('квітень', 0.8592804670333862),\n",
              " ('грудень', 0.8586863279342651),\n",
              " ('травень', 0.8408110737800598),\n",
              " ('лютий', 0.8256431818008423)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "iwmm3YQ1yl1U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "0b49a8b5-7206-4aab-e5d4-36f281ad6040"
      },
      "cell_type": "code",
      "source": [
        "ru_emb.most_similar([uk_emb[\"серпень\"]])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Недопустимость', 0.24435284733772278),\n",
              " ('конструктивность', 0.23293080925941467),\n",
              " ('офор', 0.23256804049015045),\n",
              " ('deteydlya', 0.23031717538833618),\n",
              " ('пресечении', 0.22632381319999695),\n",
              " ('одностороннего', 0.22608885169029236),\n",
              " ('подход', 0.2230587601661682),\n",
              " ('иболее', 0.22003726661205292),\n",
              " ('2015Александр', 0.21872764825820923),\n",
              " ('конструктивен', 0.21796566247940063)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "lAsW7oxszE_I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_word_pairs(filename):\n",
        "    uk_ru_pairs = []\n",
        "    uk_vectors = []\n",
        "    ru_vectors = []\n",
        "    with open(filename, \"r\", encoding='utf8') as inpf:\n",
        "        for line in inpf:\n",
        "            uk, ru = line.rstrip().split(\"\\t\")\n",
        "            if uk not in uk_emb or ru not in ru_emb:\n",
        "                continue\n",
        "            uk_ru_pairs.append((uk, ru))\n",
        "            uk_vectors.append(uk_emb[uk])\n",
        "            ru_vectors.append(ru_emb[ru])\n",
        "    return uk_ru_pairs, np.array(uk_vectors), np.array(ru_vectors)\n",
        "\n",
        "\n",
        "uk_ru_train, X_train, Y_train = load_word_pairs(\"ukr_rus.train.txt\")\n",
        "uk_ru_test, X_test, Y_test = load_word_pairs(\"ukr_rus.test.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9z6ts7DC0XmN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Learning mapping from one embedding space to another\n",
        "\n",
        "We have pairs of words that match each other, and their embedding. Find a transformation from one space to another, in order to bring the words we know to us:\n",
        "\n",
        "$$W^*= \\arg\\min_W ||WX - Y||_F, \\text{где} ||*||_F - \\text{норма Фробениуса}$$\n",
        "\n",
        "\n",
        "This function is very similar to linear regression (without bias).\n",
        "\n",
        "** Task ** Implement it - use `LinearRegression` from sklearn with` fit_intercept = False`:"
      ]
    },
    {
      "metadata": {
        "id": "fraTOQtu1YWI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mapping = ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PrzRk3ja1b_6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check where the serpen will go:"
      ]
    },
    {
      "metadata": {
        "id": "Quax6HnF1aON",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "7b75f859-181f-4f82-e538-e921ba9f2562"
      },
      "cell_type": "code",
      "source": [
        "august = mapping.predict(uk_emb[\"серпень\"].reshape(1, -1))\n",
        "ru_emb.most_similar(august)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-5c2ca20c038f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maugust\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muk_emb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"серпень\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mru_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugust\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mapping' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ih1GLNZt1nZX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It should turn out that the top contains different months, but August is not the first.\n",
        "\n",
        "We will measure percision top-k with k = 1, 5, 10.\n",
        "\n",
        "** Task ** Implement the following function:"
      ]
    },
    {
      "metadata": {
        "id": "JnmrLp9y2gNI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "763ac249-e4c2-4472-bfbd-c08a7a4036f2"
      },
      "cell_type": "code",
      "source": [
        "def precision(pairs, mapped_vectors, topn=1):\n",
        "    \"\"\"\n",
        "    :args:\n",
        "        pairs = list of right word pairs [(uk_word_0, ru_word_0), ...]\n",
        "        mapped_vectors = list of embeddings after mapping from source embedding space to destination embedding space\n",
        "        topn = the number of nearest neighbours in destination embedding space to choose from\n",
        "    :returns:\n",
        "        precision_val, float number, total number of words for those we can find right translation at top K.\n",
        "    \"\"\"\n",
        "    assert len(pairs) == len(ru_vectors)\n",
        "    num_matches = 0\n",
        "    for i, (_, ru) in enumerate(pairs):\n",
        "        <write code here>\n",
        "    precision_val = num_matches / len(pairs)\n",
        "    return precision_val"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-44-e29dcacf52c9>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    <write code here>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "-1NIvhSH2olG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "6174dbb2-27b2-4f59-846d-de895538fd59"
      },
      "cell_type": "code",
      "source": [
        "assert precision([(\"серпень\", \"август\")], august, topn=5) == 0.0\n",
        "assert precision([(\"серпень\", \"август\")], august, topn=9) == 1.0\n",
        "assert precision([(\"серпень\", \"август\")], august, topn=10) == 1.0"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-9849356ac11c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"серпень\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"август\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugust\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"серпень\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"август\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugust\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"серпень\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"август\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugust\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'precision' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "9Ml_w1Tl2r7Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "27632c52-8526-4f8a-f606-6a22b7a106ab"
      },
      "cell_type": "code",
      "source": [
        "assert precision(uk_ru_test, X_test) == 0.0\n",
        "assert precision(uk_ru_test, Y_test) == 1.0"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-1800a973eb36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muk_ru_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muk_ru_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'precision' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "-d9KQHMr2tx8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "227025a0-4541-4243-bb8e-71b7e9d3fc03"
      },
      "cell_type": "code",
      "source": [
        "precision_top1 = precision(uk_ru_test, mapping.predict(X_test), 1)\n",
        "precision_top5 = precision(uk_ru_test, mapping.predict(X_test), 5)\n",
        "\n",
        "assert precision_top1 >= 0.635\n",
        "assert precision_top5 >= 0.813"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-4d917e2b7aa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprecision_top1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muk_ru_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprecision_top5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muk_ru_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mprecision_top1\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.635\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mprecision_top5\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.813\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'precision' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "JNbDTP502urT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Improving Mapping\n",
        "\n",
        "It can be shown that mapping is better to build orthogonal:\n",
        "$$ W ^ * = \\ arg \\ min_W || WX - Y || _F \\ text {, where:} W ^ TW = I $$\n",
        "\n",
        "You can search for it through SVD:\n",
        "$$ X ^ TY = U \\ Sigma V ^ T \\ text {, singular value decompostion} $$\n",
        "\n",
        "$$ W ^ * = UV ^ T $$\n",
        "\n",
        "** Task ** Implement this feature."
      ]
    },
    {
      "metadata": {
        "id": "9de8XZ_F3v53",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "4d62decc-6499-4968-caac-81d612aba9d3"
      },
      "cell_type": "code",
      "source": [
        "def learn_transform(X_train, Y_train):\n",
        "    \"\"\" \n",
        "    :returns: W* : float matrix[emb_dim x emb_dim] as defined in formulae above\n",
        "    \"\"\"\n",
        "    <write code there>"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-48-c74613ca0d47>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    <write code there>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "8WeCadzN382y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "6f9f9ee0-e241-4bf4-f627-34a8a78af39d"
      },
      "cell_type": "code",
      "source": [
        "W = learn_transform(X_train, Y_train)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-7aba93ed7205>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'learn_transform' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "p6qaMb0E3-f9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "8a9f6c64-83bd-4af6-b7ae-25ecd4e74d6a"
      },
      "cell_type": "code",
      "source": [
        "ru_emb.most_similar([np.matmul(uk_emb[\"серпень\"], W)])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-dc2a77b7a7fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mru_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muk_emb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"серпень\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'W' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "_Nn58crh4AH0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "aed28969-9929-405a-b6c3-f2cc90b78dff"
      },
      "cell_type": "code",
      "source": [
        "assert precision(uk_ru_test, np.matmul(X_test, W)) >= 0.653\n",
        "assert precision(uk_ru_test, np.matmul(X_test, W), 5) >= 0.824"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-21b1235280e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muk_ru_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.653\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muk_ru_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.824\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'precision' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "lqgcYk-c4DE5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Writing a translator"
      ]
    },
    {
      "metadata": {
        "id": "hwi70fP6FaAN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We implement a simple word-by-word translator - for each word we will look for its nearest neighbor in the common embedding space. If the word is not in the inserts - just copy it."
      ]
    },
    {
      "metadata": {
        "id": "0etAHUks4JOr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "e944f111-66a5-4810-9d82-dc30cd79c915"
      },
      "cell_type": "code",
      "source": [
        "with open(\"fairy_tale.txt\", \"r\") as in f:\n",
        "    uk_sentences = [line.rstrip().lower() for line in in f]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-52-78d154fd4db8>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    with open(\"fairy_tale.txt\", \"r\") as in f:\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "JK_FJGmn4N7V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "df4a7306-cdfc-476b-db0b-b07eca84fd23"
      },
      "cell_type": "code",
      "source": [
        "def translate(sentence):\n",
        "    \"\"\"\n",
        "    :args:\n",
        "        sentence - sentence in Ukrainian (str)\n",
        "    :returns:\n",
        "        translation - sentence in Russian (str)\n",
        "\n",
        "    * find ukrainian embedding for each word in sentence\n",
        "    * transform ukrainian embedding vector\n",
        "    * find nearest russian word and replace\n",
        "    \"\"\"\n",
        "    <implement it!>"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-53-ae4784ae9ae9>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    <implement it!>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "H47pbFyk4P6D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "fb95e6f3-6941-4e11-b2da-92042da436c0"
      },
      "cell_type": "code",
      "source": [
        "assert translate(\".\") == \".\"\n",
        "assert translate(\"1 , 3\") == \"1 , 3\"\n",
        "assert translate(\"кіт зловив мишу\") == \"кот поймал мышку\""
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-4934025af253>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1 , 3\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1 , 3\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"кіт зловив мишу\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"кот поймал мышку\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'translate' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "PAVWK7mE4RYU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "6987d9bc-fb2c-4dc7-9535-1bef03ce045f"
      },
      "cell_type": "code",
      "source": [
        "for sentence in uk_sentences:\n",
        "    print(\"src: {}\\ndst: {}\\n\".format(sentence, translate(sentence)))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-7af83f311978>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muk_sentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"src: {}\\ndst: {}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'uk_sentences' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "_5GrChTeFqIg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Additional materials"
      ]
    },
    {
      "metadata": {
        "id": "HwffxpbmFwDh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Read\n",
        "### Base:\n",
        "[On word embeddings - Part 1, Sebastian Ruder] (http://ruder.io/word-embeddings-1/)\n",
        "[Deep Learning, NLP, Christosher Olah] (http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/)\n",
        "\n",
        "### How to cluster meanings of multi-valued words:\n",
        "[Making Sense of Word Embeddings (2016), Pelevina et al] (http://anthology.aclweb.org/W16-1620)\n",
        "\n",
        "### How to evaluate embeddings\n",
        "[Evaluation methods for unsupervised word embeddings (2015), T. Schnabel] (http://www.aclweb.org/anthology/D15-1036)\n",
        "[Intrinsic Evaluation of Word Vectors Fails to Predict Extrinsic Performance (2016), B. Chiu] (https://www.aclweb.org/anthology/W/W16/W16-2501.pdf)\n",
        "[Problems With Word Of Word Embeddings Using Word Similarity Tasks (2016), M. Faruqui]\n",
        "[Improving Reliability of Word Task and Performance Measurement (2016), Oded Avraham, Yoav Goldberg] (https://arxiv.org/pdf/1611.03641.pdf)\n",
        "[Evaluating Word Embeddings Using the Representative Suite of Practical Tasks (2016), N. Nayak] (https://cs.stanford.edu/~angeli/papers/2016-acl-veceval.pdf)\n",
        "\n",
        "\n",
        "## show\n",
        "[Word Vector Representations: word2vec, Lecture 2, cs224n] (https://www.youtube.com/watch?v=ERibwqs9p38)"
      ]
    }
  ]
}